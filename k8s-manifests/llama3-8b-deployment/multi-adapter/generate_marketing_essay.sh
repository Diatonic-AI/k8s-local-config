#!/usr/bin/env bash

echo "Setting up connection to Llama model..."
kubectl port-forward -n llama3-multi-adapter svc/ollama-simple-fast 11434:11434 &>/dev/null &
PF_PID=$!
sleep 3

echo "Generating marketing essay (this may take a few minutes)..."
echo ""

PROMPT="Write a comprehensive marketing essay about the future of artificial intelligence and digital transformation in business. The essay should be approximately 10,000 characters long and cover topics including: AI-driven customer experiences, predictive analytics, automation, personalization, competitive advantages, implementation strategies, ROI considerations, and future trends. Make it engaging, professional, and suitable for business executives."

RESPONSE=$(curl -sf -X POST http://localhost:11434/api/generate \
    -H "Content-Type: application/json" \
    -d "{\"model\": \"llama3:8b\", \"prompt\": \"$PROMPT\", \"stream\": false, \"options\": {\"num_predict\": 2500}}" 2>/dev/null)

if [ $? -eq 0 ]; then
    echo "=========================================="
    echo "  MARKETING ESSAY"
    echo "  Generated by Llama 3 (8B)"
    echo "=========================================="
    echo ""
    
    ESSAY=$(echo "$RESPONSE" | jq -r '.response')
    echo "$ESSAY"
    
    echo ""
    echo "=========================================="
    CHAR_COUNT=$(echo "$ESSAY" | wc -c)
    WORD_COUNT=$(echo "$ESSAY" | wc -w)
    echo "Statistics:"
    echo "  - Characters: $CHAR_COUNT"
    echo "  - Words: $WORD_COUNT"
    echo "  - Generation time: $(echo "$RESPONSE" | jq -r '.total_duration / 1000000000 | floor')s"
    echo "=========================================="
    
    # Save to file
    echo "$ESSAY" > marketing_essay_$(date +%Y%m%d_%H%M%S).txt
    echo ""
    echo "Essay saved to: marketing_essay_$(date +%Y%m%d_%H%M%S).txt"
else
    echo "Error: Failed to generate essay"
fi

kill $PF_PID 2>/dev/null
wait $PF_PID 2>/dev/null
